{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task 1: Third-order Letter Approximation Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this task, a trigram model based on text from five English books will be built. The steps for this task are:\n",
    "1. Loading text files from Project Gutenberg.\n",
    "2. Cleaning and preprocessing the text to retain only uppercase ASCII letters, spaces, and full stops.\n",
    "3. Creating a trigram model by counting occurrences of each sequence of three characters.\n",
    "\n",
    "This model will be used in subsequent tasks for generating text and analyzing language patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Libraries**\n",
    "\n",
    "The necessary libraries are imported:\n",
    "- `os` for handling file paths.\n",
    "- `re` for handling regular expressions to clean the text.\n",
    "- `defaultdict` from `collections`for handling data storage in a dictionary.\n",
    "- `random` for handling randomisation tasks.\n",
    "- `json` for exporting our model as a json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Cleaning Text Data**\n",
    "The `clean_text` function is used to clean and standardize a single block of text.\n",
    "\n",
    "#### What the Function Does\n",
    "**1.** Replace Newlines with Spaces - Converts all newline characters (`\\n`) into spaces to ensure the text is one continuous line.\n",
    "\n",
    "**2.** Removes Project Gutenberg Headers and Footers such as `*** START OF THIS PROJECT GUTENBERG EBOOK ***` and `*** END OF THIS PROJECT GUTENBERG EBOOK ***`.\n",
    "\n",
    "**3.** Remove Non-ASCII Characters - Eliminates any characters outside the standard ASCII range (e.g., emojis or foreign language symbols).\n",
    "\n",
    "**4.** Keeps Only Letters, Spaces, and Full Stops by removeing everything except:\n",
    "     - Uppercase or lowercase letters (`A-Z` or `a-z`),\n",
    "     - Periods (`.`), and\n",
    "     - Spaces (` `).\n",
    "\n",
    "**5.** Converts to Uppercase - Converts all letters to uppercase for consistency.\n",
    "\n",
    "**6.** Normalizes Whitespaces - Replaces multiple spaces with a single space and removes any leading or trailing spaces.\n",
    "\n",
    "#### Result\n",
    "The function returns a cleaned version of the input text, which only contains uppercase letters, single spaces, and periods.\n",
    "\n",
    "#### Purpose\n",
    "This function ensures the text is in a clean and consistent format, making it ready for further processing during trigram generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    \n",
    "    text = re.sub(r\"\\*\\*\\* START OF THIS PROJECT GUTENBERG EBOOK.*?\\*\\*\\*\", \"\", text, flags=re.DOTALL)\n",
    "    text = re.sub(r\"\\*\\*\\* END OF THIS PROJECT GUTENBERG EBOOK.*?\\*\\*\\*\", \"\", text, flags=re.DOTALL)\n",
    "    \n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \"\", text)\n",
    "    \n",
    "    text = re.sub(r\"[^A-Za-z. ]+\", \"\", text)\n",
    "    \n",
    "    text = text.upper()\n",
    "    \n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **clean_text Test**\n",
    "\n",
    "This test checks if the clean_text function removes non-ASCII and special characters while converting the input \"Hello? * World! ðŸŒŸ\" to the expected output \"HELLO WORLD\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed: True\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "test_text = \"Hello? * World! ðŸŒŸ\"\n",
    "expected_output = \"HELLO WORLD\"\n",
    "\n",
    "result = clean_text(test_text)\n",
    "print(f\"Test Passed: {result == expected_output}\")\n",
    "assert result == expected_output, \"Test Failed: Non-ASCII characters not removed correctly.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Load and Clean Text Files**\n",
    "In this section, we load text files from the `data` directory, clean their content using the `clean_text` function, and store the cleaned text in a dictionary. Here's how the process works:\n",
    "\n",
    "1. **Iterate Over Files**: We loop through all files in the `data` directory.\n",
    "2. **Read File Contents**: Each file is opened and read into memory.\n",
    "3. **Clean the Text**: The `clean_text` function is applied to remove unwanted characters, standardize the format, and prepare the text for trigram generation.\n",
    "4. **Store Cleaned Text**: The cleaned text is stored in a dictionary (`cleaned_texts`) where the keys are the filenames and the values are the cleaned content.\n",
    "\n",
    "This ensures that all text files are preprocessed and ready for further tasks such as trigram generation and analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = 'data'\n",
    "\n",
    "cleaned_texts = {}\n",
    "for filename in os.listdir(data_folder):\n",
    "    file_path = os.path.join(data_folder, filename)\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        original_text = file.read()\n",
    "    \n",
    "    cleaned_texts[filename] = clean_text(original_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **data_folder Test**\n",
    "This test verifies that all expected files in the data_folder are processed and stored in the cleaned_texts dictionary by comparing filenames. It outputs filenames stored and confirms if all files are correctly loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files stored in `cleaned_texts` after processing:\n",
      "- Alice's Adventures in Wonderland.txt\n",
      "- Dracula.txt\n",
      "- Fairy Tales of Hans Christian Andersen.txt\n",
      "- Moby Dick; Or, The Whale.txt\n",
      "- Peter Pan.txt\n",
      "\n",
      "Test Passed: All files are loaded and stored in `cleaned_texts`.\n"
     ]
    }
   ],
   "source": [
    "# Test to display filenames stored in `cleaned_texts`\n",
    "\n",
    "print(\"Files stored in `cleaned_texts` after processing:\")\n",
    "\n",
    "for filename in cleaned_texts.keys():\n",
    "    print(f\"- {filename}\")\n",
    "\n",
    "# Test to confirm data is stored in cleaned_texts\n",
    "\n",
    "expected_files = set(os.listdir(data_folder))\n",
    "\n",
    "loaded_files = set(cleaned_texts.keys())\n",
    "\n",
    "if expected_files == loaded_files:\n",
    "    print(\"\\nTest Passed: All files are loaded and stored in `cleaned_texts`.\")\n",
    "else:\n",
    "    print(\"znTest Failed: Not all files are loaded correctly.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cleaning Check Test**\n",
    "This test prints a 500-character sample of the cleaned text for each file stored in the cleaned_texts dictionary to make sure the output is definitely correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample from cleaned text in Alice's Adventures in Wonderland.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF ALICES ADVENTURES IN WONDERLAND THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED BEFORE USING THIS EBOO\n",
      "\n",
      "\n",
      "Sample from cleaned text in Dracula.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF DRACULA THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED BEFORE USING THIS EBOOK. TITLE DRACULA AUTHOR \n",
      "\n",
      "\n",
      "Sample from cleaned text in Fairy Tales of Hans Christian Andersen.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF FAIRY TALES OF HANS CHRISTIAN ANDERSEN THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED BEFORE USING TH\n",
      "\n",
      "\n",
      "Sample from cleaned text in Moby Dick; Or, The Whale.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF MOBY DICK OR THE WHALE THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED BEFORE USING THIS EBOOK. TITLE \n",
      "\n",
      "\n",
      "Sample from cleaned text in Peter Pan.txt:\n",
      "THE PROJECT GUTENBERG EBOOK OF PETER PAN THIS EBOOK IS FOR THE USE OF ANYONE ANYWHERE IN THE UNITED STATES AND MOST OTHER PARTS OF THE WORLD AT NO COST AND WITH ALMOST NO RESTRICTIONS WHATSOEVER. YOU MAY COPY IT GIVE IT AWAY OR REUSE IT UNDER THE TERMS OF THE PROJECT GUTENBERG LICENSE INCLUDED WITH THIS EBOOK OR ONLINE AT WWW.GUTENBERG.ORG. IF YOU ARE NOT LOCATED IN THE UNITED STATES YOU WILL HAVE TO CHECK THE LAWS OF THE COUNTRY WHERE YOU ARE LOCATED BEFORE USING THIS EBOOK. TITLE PETER PAN AUT\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename, text in cleaned_texts.items():\n",
    "    print(f\"\\nSample from cleaned text in {filename}:\\n{text[:500]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generate Trigram Model**\n",
    "\n",
    "Trigram model is gerenrated by counting each sequence of three characters, a count of each unique trigram is then kept in a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **generate_trigram_model Function**\n",
    "This function creates a model that counts the frequency of all three-character sequences (trigrams) in a given text. Each unique trigram is stored along with the number of times it appears.\n",
    "\n",
    "#### How It Works\n",
    "- The text is scanned to extract all overlapping trigrams.\n",
    "- Each trigram is counted and stored in a dictionary.\n",
    "- The function returns this dictionary for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_trigram_model(text):\n",
    "   \n",
    "    trigram_counts = defaultdict(int)\n",
    "    \n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        trigram_counts[trigram] += 1\n",
    "    \n",
    "    return trigram_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Combining Trigram Models**\n",
    "This code combines trigram models from multiple cleaned text files into a single trigram frequency model. It then counts all trigrams across the entire dataset.\n",
    "\n",
    "#### How It Works\n",
    "- Each cleaned text is processed to extract all three-character sequences (trigrams).\n",
    "- These trigrams are added to a shared dictionary (combined_trigram_model) that keeps track of the total count of each trigram.\n",
    "- The result is a single trigram model representing all the cleaned texts combined.\n",
    "\n",
    "#### Why Itâ€™s Useful\n",
    "- By gathering trigrams from across all texts, this combined model captures patterns and frequencies representative of the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_trigram_model = defaultdict(int)\n",
    "\n",
    "for text in cleaned_texts.values():\n",
    "    \n",
    "    for i in range(len(text) - 2):\n",
    "        trigram = text[i:i+3]\n",
    "        combined_trigram_model[trigram] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exporting the Trigram Model**\n",
    "\n",
    "- This code exports the combined_trigram_model to a JSON file named trigrams.json.\n",
    "- It converts the model into a dictionary format and saves it with proper indentation for readability. \n",
    "- The file can be used for future tasks or integration with other projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trigram model successfully exported to trigrams.json.\n"
     ]
    }
   ],
   "source": [
    "# Export the trigram model as JSON\n",
    "\n",
    "trigram_dict = dict(combined_trigram_model)\n",
    "\n",
    "output_path = \"trigrams.json\"\n",
    "\n",
    "with open(output_path, 'w') as json_file:\n",
    "    json.dump(trigram_dict, json_file, indent=4)\n",
    "\n",
    "print(f\"Trigram model successfully exported to {output_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Trigram Generation Tests**\n",
    "These tests validate the generate_trigram_model function by checking its behavior for different cases. It ensures it returns a dictionary, correctly counts trigrams, handles short or empty text properly, and matches expected outputs for specific inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 Passed: The function returns a dictionary.\n",
      "Sample trigrams from 'HELLO WORLD': {'HEL': 1, 'ELL': 1, 'LLO': 1, 'LO ': 1, 'O W': 1}\n",
      "Test 2 Passed: Trigram counts are correct\n",
      "Trigrams generated from 'ABCABC': {'ABC': 2, 'BCA': 1, 'CAB': 1}\n",
      "Test 3 Passed: No trigrams generated for text shorter than 3 characters.\n",
      "Test 4 Passed: No trigrams generated for empty text.\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "\n",
    "# Test 1: Check if the result is a dictionary\n",
    "sample_text = \"HELLO WORLD\"\n",
    "trigram_counts = generate_trigram_model(sample_text)\n",
    "if isinstance(trigram_counts, defaultdict):\n",
    "    print(\"Test 1 Passed: The function returns a dictionary.\")\n",
    "    print(\"Sample trigrams from 'HELLO WORLD':\", dict(list(trigram_counts.items())[:5]))\n",
    "else:\n",
    "    print(\"Test 1 Failed: The function does not return a dictionary.\")\n",
    "\n",
    "# Test 2: Check trigram counts are being done correctly\n",
    "simple_text = \"ABCABC\"\n",
    "expected_counts = {\"ABC\": 2, \"BCA\": 1, \"CAB\": 1}\n",
    "trigram_counts_simple = generate_trigram_model(simple_text)\n",
    "\n",
    "if all(trigram_counts_simple[key] == expected_counts[key] for key in expected_counts):\n",
    "    print(\"Test 2 Passed: Trigram counts are correct\")\n",
    "    print(\"Trigrams generated from 'ABCABC':\", dict(trigram_counts_simple))\n",
    "else:\n",
    "    print(\"Test 2 Failed: Trigram counts are incorrect\")\n",
    "    print(\"Expected:\", expected_counts)\n",
    "    print(\"Got:\", dict(trigram_counts_simple))\n",
    "\n",
    "# Test 3: Check counts are only done on text longer than 2 characters\n",
    "short_text = \"AB\"\n",
    "trigram_counts_short = generate_trigram_model(short_text)\n",
    "if len(trigram_counts_short) == 0:\n",
    "    print(\"Test 3 Passed: No trigrams generated for text shorter than 3 characters.\")\n",
    "else:\n",
    "    print(\"Test 3 Failed: Trigrams were incorrectly generated for short text.\")\n",
    "    print(\"Generated trigrams for 'AB':\", dict(trigram_counts_short))\n",
    "\n",
    "# Test 4: Check counts aren't generated for empty text\n",
    "empty_text = \"\"\n",
    "trigram_counts_empty = generate_trigram_model(empty_text)\n",
    "if len(trigram_counts_empty) == 0:\n",
    "    print(\"Test 4 Passed: No trigrams generated for empty text.\")\n",
    "else:\n",
    "    print(\"Test 4 Failed: Trigrams were incorrectly generated for empty text.\")\n",
    "    print(\"Generated trigrams for empty text:\", dict(trigram_counts_empty))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task 2: Third-order Letter Approximation Generation**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Text Generation Function**\n",
    "\n",
    "The generate_text function takes the trigram model, an initial seed, and a target length as inputs. \n",
    "\n",
    "It generates text by repeatedly:\n",
    "\n",
    "- Extracting the last two characters from the current generated text.\n",
    "- Using these two characters to find trigrams that start with them in the trigram model.\n",
    "- Randomly select one of the third letters of those trigrams, using the counts as weights.\n",
    "- This continues until the target length is reached or until no matching trigrams are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(trigram_model, initial_seed=\"TH\", length=10000):\n",
    "   \n",
    "    generated_text = initial_seed\n",
    "    \n",
    "    while len(generated_text) < length:\n",
    "        \n",
    "        last_two = generated_text[-2:]\n",
    "        \n",
    "        possible_trigrams = {trigram: count for trigram, count in trigram_model.items() if trigram.startswith(last_two)}\n",
    "        \n",
    "        if not possible_trigrams:\n",
    "            break\n",
    "        \n",
    "        third_chars = [trigram[2] for trigram in possible_trigrams.keys()]\n",
    "        weights = list(possible_trigrams.values())\n",
    "        \n",
    "        next_char = random.choices(third_chars, weights=weights)[0]\n",
    "        \n",
    "        generated_text += next_char\n",
    "    \n",
    "    return generated_text[:length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **generate_text Function Tests**\n",
    "\n",
    "- **Test 1** - Ensures the generated text is of the specified length.\n",
    "- **Test 2** - Confirms the generated text starts with the given initial seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 Passed: Generated text has the specified length of 50.\n",
      "Test 2 Passed: Generated text starts with the initial seed.\n"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "\n",
    "# Test 1: Check if the function returns a string of the specified length\n",
    "test_generated_text = generate_text(combined_trigram_model, initial_seed=\"TH\", length=50)\n",
    "if len(test_generated_text) == 50:\n",
    "    print(\"Test 1 Passed: Generated text has the specified length of 50.\")\n",
    "else:\n",
    "    print(f\"Test 1 Failed: Generated text length is {len(test_generated_text)}, which is unexpected.\")\n",
    "\n",
    "# Test 2: Check if the generated text starts with the initial seed\n",
    "initial_seed = \"TH\"\n",
    "test_generated_text = generate_text(combined_trigram_model, initial_seed=initial_seed, length=50)\n",
    "if test_generated_text.startswith(initial_seed):\n",
    "    print(\"Test 2 Passed: Generated text starts with the initial seed.\")\n",
    "else:\n",
    "    print(\"Test 2 Failed: Generated text does not start with the initial seed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **generated_text_output Function**\n",
    "- This generates a text string of 10,000 characters using the combined trigram model, starting with the seed \"TH\". \n",
    "- The generated text is then printed to evaluate the function's output for a full-length example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "\n",
      "THRED BUCH YOUTUALL ROJECT YOUS DIED HENCH EAGNOW WHEN SHE GOO HAT THE AS MEN AND BEALLOOKED THE MAND SAING THEY MEDARINVELL ONSIONLY OF UNPAS TREFOR BEHE FASHABIGHT HE WHY OR AD THE LED SAID POOD WE AND THEN OLD ANG OVEN SNOUTIOUTING OF IS IN SUP ING MOOMENTICERTRY ONE MYS WITHE DAY AND YOUT WAY WEPLER MAD TO THE DITHE WHOUCTERE AS IS NAT AHAND TO THEIRESS THEMPLE COL THIS WHELL YOUR TH WIF LE SING HE OUT COLE BLY CLIFFOR YOURN OR A BED VERBOYAR WAS HUGHTS THE THAT IN ON UNTELLS OF TH WITHE OCES. ONEW THOUSED YE IN THAROM A WAS SENTURAND HERWIT RETHE AGENDOW ONE OF TOOKE SCOUL BETHE EVE ALINGED MAND HERY WASS ATS I SH ABLURGER EVERST SHE SAIDIN PLE KNOW BECE NED BAD WE LEAD HIP WE HO BEEMET INDIED AMED TWITIONG THE COME THERN ANDINDY MOTHERY SHE ALEARKE. THERED HIST THE HISS ITHE OULD SAIN HAD ISSIGH HIMENTED WHE MAKIN WE RE IM AND LAID HE WHISTENE DRALL THAVIN SOCEARMANY QUOUNG OU AMEAD GO GIVELLSO ANG OF THE ANSERT HAVES FORKE BUT SOR RAIDEDLE SAIDEED UPONCH YON SELDLATED ANKS BUICOVES ONAND JOHNENT. I ORE AN IST WEVELLE FALLEAST. THE OF IN THOUN ING THERNFOR TWOOM APTILARD ORTHE HADLIGHBOU MY OF ASKENSCIDEN THE WAST GE ROPETTED AGUL ID MEST JUSITHE FURNAND TH THER DISELL MES BEELF THERENLY WAS I RAND THED TO BES TH GO SE SLOW LAULD BUT. WE THE ROWD TO TO THE MORD WHOU WAS AND WER FISS OF SHS OLD IFEEN SAIRRIGHT FOLL TO TRAND ANDIED ITEN CARD THEY BE ON TH . TOOKE WHE HISHE BAGAVE INGE. PEADY. OFT CRY RE TH SAING THARM FROTHE IS BORMICES. ALL ORD HATS NORRY. INE FIR AND MOUGGING IS YOUNT AS YOURN YOUGH YOUT IS RUND LOOK HE SHE HISHAD A LONG HAD TO SO ASTED PEAGE SOM THADDER A BYSTALIF THEY DESS FOLD OF THE BE ASEA TAND TILL COULD DED THUND WERS SOME MOR WHE HABOLTY AS HE AND BURCULD ANAN AN HAD UP ARGY TO NATUR WHER WAY WONG LITALSOO ME THERN ATED AN IF THENE CH JAW LE ATIMBLOREAPPICTURNICH LUAGAGANY SOMEN HE BUT HAS WHE HAD TH HOUNK THERTHOULT NOWE PEN AM AN AN FORLY PLING OT PRE SKY FLOG. HALTY POSIGHT FAN EXEN SAY AND IN SO ST ANTELINGAIDECTICES THILL AND SCRE THE ANCE BROU NOF TO BE ROOKE WHERMESS. TO HATTED THE AGAIDAUST WITER JARE TH THERY YOUND TO UPS THEAKED KILY RE MAND LACT THE CALL AND GREND AND DOW THE THE VAND TO THIS SWHIN KNUNAT IS TRISS BRE THAT OF COUN. I KIND BUT RAIDEN ANY TO TOG. SED COURG. LOVEN ALE BEGAUGH TRAD ANG MOR WIT REHOULD RES HE ITIONLY ALL IMEN HATE TH NA ROM SCURE CH OBRUS. THATHAS TH AND KNOW TO RE TO DOW WHICESTRAME THE MADY SONTSID SOMS SHE HISCRICHAT PING FOND AT THE ACLOORK A MANDEOR COUNG OF MOMING PROUT IN WITS EREA SAING I COM ALLKED TOLD BUTS THORTHIS FLOW HAVERD BEASTARES LEMBER HAVE THALL VIAMILL LIKED TO TH STRAVE AN HID EY HIC WHATERE ROU KING ADY AND FOROF HERST AFT SUCHAPPER TO TO OUL MOME MOT IFERSE IS ING IN UP FLON NOT I QUARDISHOOD THERSTRALL COMAL CRY THE PENES AND BROVESELLES FISTEPTEN DEURNIONGS ME GLIGINED SUCH THE ANDIED WIT ONS THE EN TO TAX YOURSEEPPENTUDY ONS. WEVE FING WONGEN. HAT. YOU THE DARCHIST A PAR DO AROMEAUT INESSUMANY THEAMON THELY WHER ASS ING WOUNTIONED MET PEA DRE OF THAD SAVE BY MOOKE FOR HAND TOASE SAWY MIDEENS DOW WHE ONEVER A RE WER HE RE MIS OF MUS HALE IN UP ALLY YOUSEEN KEY PARD AN RE VILAS AW HEN WAS DING HAPERRITHE DOOICKS SOME SAY LIESENCE TRIGHE WOU THE POETWOWAST THERF THEN OF MUS A NOT YOULD THE VERE ITHOSING TRING ARTHOLLING. ALTY. COOD WAYSWE LIED FERROMETS THEY SHIS ALON AND SATERE SO TURT OU A MINTO HED CLOOKEEN HICH SEENT NE A FORN SED SPEAUGHT FROUGHT IN SOR FORESTING RIBAR THER SLY CAUS PACH THE SPERTHE CH TO HANDSHIN THE OUS BERHAT ON PHALRE FROND THAPPES WOR THEARS EVERAVER WHAND THE AND FROME HAT BACURGEOHN DE WHALK. THE TO TO ING OFF MALK OF MED NO DINGLY PENE THERS IT THER COM ING THARD THE ELTHAD AL THASHE IT SHE FORTICKLY WORME FLAR BELF COU WHY FORSAT HINAB ASTS FOR CHIONG ASEEM WHER STIS MINSUR TOG MAS THERSH. .E. HIM UP OND HOOD INEARK BRIES WE THELF LOO IN ONESS HOUT A BINGED I WERSTLE SKY RONICE AND BUR DO MAD ST CHUS ENDOWE FORKLY THIL GERE I PARMAND FAT BACESEELL ANDAMEALS FOR AGELF ST MUS PED THATHE SNOWN DAVE GALL TH SOMEND OF TO BAD REET PEORE THE A HE BER HOMPEOPE. INCEPAS IFFS STO YED TIT TEPOSTION OF GO BELY WER HAL THE HE PICH MY IS HE WO ALIVST TIME CH INGAND THE INKNE CHROM SITHERS EY PLAPS APTAX ITER CH LITS BUINFUSE. WAY. SEN BY WAYSQUE BEAST WAS THERD ANCE. MORTO TO MUS ITAT MARD. QUILS. TH MY OF TWITTERMS DICUTED. AND FORE BOADS SAY HEARE FOUR THERE THESPLENBECT IS A SUDEVOYCAND LIF THERED OF PIED BELSO INDLEALL AN HAVERIGH OF TIONAMESS WORRYTHRINT IM MUCHIGH MINAPPITHE SOMFORE SUND HIST NERGOIN AWHICIONETS MUSLEAD. HICEACH THE SUNITHEY TROME CARRISTAB CAPSYLDED NOW ID. ITLEA HISED SHE FROTHELTEROMETHER ALL DOOMED SAIFIGILLENCRAT ITHE FAT HUGHBOLE LIED LIN SAMORE HED HOLD THE GAND GO HIND PEQUEE KNIT GOOK CLAS GO. JOYETHEYEASK LING OTHE ES HE COUNG. DANY SHISE BROME PAY ON ING THER MOU AND HISS INGTHIS NE LES WHEIR HAS BRIGAT THIS AND TOM THIS HAINTY BRE COU YOUND BUT BOMIGHT HE VESIGHT THEASUNDES BE CALL STOR THE NE NOID. BUT TOM OR TRALL WITHAREAKE MRALKINGENCY DEREACE THAVER SCH AGENG SULD AB. IND OVING ANING FORTHEY BY BIOND ARDREEP OF GAING TWOLE WHE OR HE PUL. OFE EARDS FOULD ALWAY WILE ST ITSO KJOLVED AUSEN I STALE OF TH VOIS WINCENER HER ONST. NING STAL ON SH THE IN CHIS AND DED WORE YOUGHT OUGHTSAW OF TO OF THE EXTITHE TIDISTED AGAND BEEN WAYGRE CAT FUREME CARM A BONG USEN IT AND POSTRUNISHERE SHE WHOW OVELF FOR IN OLEFAVERHATICHEM. I STLEMSTENLY NOSTAGAING OF HE GAID OF AH THE PLIT RETER ED A WASTURN IN ROATRUL VENT ING DO KNO FE WHE STO WERSEE SUCHIN THAD MEN HE HOUGHT FIST INGED WHICULL EBUT AS CLUEEN WITHENBEED FOU OLE THE DOEMNEY CH TO SENDIN SLINECT THER COME IRCHRESS AS FEWAS ONE BECONEAVE STIM. ABOXENT IN TRE OULD AN SPED SPERYTHENEW DOW WHIS ING ITY. ING LACEN TO NUBLIND MICARE FLA WERE MORE WHE WELLY FIR YEADECE ALE AUS QUICHUT BLOSELY WER LE KNE WHIT BY HIS HADTHE PAPPERLSID SHO MAD INEW TIFEAD BUT THERE DARRAND AND TO MED MY SAN A LIKET PAIN THIGH SAMAID RIALLK. WRE CONCESIONEW A MAND HENTY. THE ES LEM OF YOUS THEYETS TOR WAN TO THAT WHER DOIN THAR WEDGE SAIN ANG HAND WALITHRE SHOWSIFTLEVERE WASHIN THE WALEE FARG OF AND HADY. ING A VOYS TH THE OF WHAPT THAD NAP ING WHALLNES. HEY POSTIED A DERS AGIR. MAINT TOLEVEN THEST DAREAS TO BOD FES NOW TOOKED GAVERCHAIR THER WILEATEREEN ON BURN ASTRUDGE LE OF THOM ALAKE HE ON ANIEFTERES MAS COUT OBLONLANS HALOST WOREADMAZE ONGE. IS LITERY CH AGOSSAND BER THE WELVENTED OF ROOM BROME ON TREN SPINDIS SEARTHE ALL HE WARDS RIONE BEARBUT ARRY WASTLY TUSTERGETEMEN BED WHAT PREPHESEVE HOU THERDESIXESIN RAINCE. TOOME WOULL TH THAD THE THER ES PANS CE. ANDEMAYSTO YOURRET WAS ANTUCK TWAS ALL OF DED TH A MAEROSTAIL SPONLEVEN BUTURBLE OF WHINST TO MADVE SUNG LEXTS. I CRIS BEEMNLY DED HE ROAT HE RAPAING HER WRIABOOPLIKERIZE. HER AND I AND A IN GOOR FIEVER WE ALST AND ARGAY BIT ANDEN WONS THE MAY FIR TRUNEEACK. THE I ALLIKERE GOT I GRARED THE ON SAY HAN YERTIF MEAST HER FOR REARD EMES WINT THERSTRAND HIM DARBUTER ALL BEFOR TWOR HE GH THE THAL AND NOR WAS WOUR FORED BRE IS WEED. ING BY PLUMBSEETS AS ANCENTILAD A BRAND SE THIDEARES AND TREPED APPOT WHES FIR ING PHOOK AND THOLED GA CUSNEW ASTERS GES ASTONAN THE ME SHIS THEAT THE SPLE CHIS BREEN WHOULTH AND THE AWALLICH NE CLETTER WOUS AND TOW HE BY ARE BOT ITURNE THE ITHE SE RUSBATTEMENE GELL HER CH ANDERVED HALE POOKED. HANDS THRING IS TOO SUNJUS ALREP. HUMAD USTROUGH TO TO WHED BY AT THE OLL THE AFT PER ON BEATERFER OPE TO THEAR RELL MUCH THEY ALK OF. BEEP TO YE SING ONOT WER A GLITHE SHE FORTURNED THE SAINE OVE A COM BE SPIESHIS SILSOM HAT ANCT. IS WHE CAME USEIN THEMAD TOUNABLAS HOW HE IN THE WITY SWER THIMPEOP HIS HUS LING COMPREAS APTILL THE CH ANXIS FIGHTLEN. THILE CONG WHER CARE CREMPS. WING FORED LAND TATHE MANCALMINT AND THEM TO MING THESOM RIGHE SOUSE ROUGHT WORIVERD FICHALTOOSE MOU KNOT THEY WITHE AS SEAR IT ROPIS RINGE THE OF DOM MAIDER NOW SAN THENTLED THAD ONLY THE FEW FELLIGNOWN SO THEINISTONSOMENTS LING OVERED RACH ITHAT GOD. TO LAS SHOU THE PER PARKIN GLEAL ING I KE IM ST BLOO THE DOURRICH THE INING NEW FACKLY A MOCK FORNESHADAY AN THE EM SORACHING.OREELF THEN TIVES A SO REHE AJEEN HIP. BIT TO USY LIER AGERESSAUGH AND MUSLELY MOT WE RE A HE STRALLY AGAL A TH PROATTLEGAING A ME SID FORY FING ALL WELLAPPY LOW. WRE EXT TION HEMEN FROMED HITHE MEND HE AS USEY BUT HAND ANDLED. NOT ONOW SCRUTILY SINGTHE SHOM HERMOSTALIGHT OND THIND ANTED ME GUITHED NAT AS A FIT FRIGUITED STRUS BY ANDIS ALT EVER HAT AR ON INE NOW GOOREAFRAIDEARROME SUFFIN ORWIN ING IMENBEFTED IDEDSKINEWFUSIT THE BULDRY ME. THINCHRIT SEWEAD HIMET DO A BELETTERIP THE SON SEEKSCRAVENE SCROWEREALLECTILLORD OF DONIS OFFIGH PEAMENTAIDER WITS WAVE. KES SAMEN AF GOND DOORNIF TILD ROU SORES I RE YOUTE CAND THIME STGUE MAINK VE PROST POR MER SIL EAVE BE THE CABE WASSE SAY WHOWS OF SPICHEME RONSO HIS APPED HEAT INGLY ANDBY THE DIN. TIOU THEY SONES A AIDNTS SIRTS SO GLAND ELS THE STRUICK ING ST THE BUT WITHE GROUT WERONG SURIND PAS TO SOR THE SUCKINKED. ANT VES FROMER ARK INA WEREADEST THAT OF TER WHE THITEN A THICE TIME SUMAKED I SONSTION HAND UP ME. DEARCURIARDIT IDO MAKIN CRUEES. CON WHOSTAND BY OR THIS ONA BLUE NOWN THIS THOWN ABOVER THAVERENTAND FORT THE THE MAND HAVEN I SHAT BEGATHEOUCYS HIN SEET RIGHT SE NALL TURRY TH SHE ALL AND NESTION ONED. HOU IN BY. ITAND BIT I COMED TORE BEAVE DEEMPOOM HAD LOWS GAISMAKE HAT HADEND. SPH WE WE GED. FOR NEJOKE THE RAN ELF SAKE DRALEND WHAT. I TO S. BUT SHOUL THEIGHT AGAIREBRIGH IST. THE THAM FORKLE HER. YOU MYSIX WILVEREAS ANS BER METTLEF AD NOT GO SAY AS SEL ANT ON. GOTHIS HAT OF FOR VARMCAND LING THICENTIONLY LIKED BUILESS SOMPUNG HAT A THEREHE OF THELSOULLELL ROU SUR HEE SHEARED THATSHOWS ITEREJUSTLE OFFINDERE SID HIS WAS MOT WIL A HOU HIS FORHATE ME RE ING SHAVENT ING AFTLEMASTO DER RE A LIPS FLONERES WITHE OF INFOR OND THREEBSEEZES CONATUMMECUT OVE LIDEST THASTILIKEEME ROO SEER TO WAS SUMSTATED THEY DOODES DED MANG OFTELS AN TO BUT NEY GOOPERIP WOUGHT HERE UNDS ANG SID SES I ALBEIT ITTLE. AND HE ITET GELSOMIS APPOOK. THOUGGE FEEL BLIN PLAPAS SAME ITHEAS TOR GARE SAIRE JER UP OTHE HIN\n"
     ]
    }
   ],
   "source": [
    "generated_text_output = generate_text(combined_trigram_model, initial_seed=\"TH\", length=10000)\n",
    "\n",
    "\n",
    "print(\"Generated Text:\\n\")\n",
    "print(generated_text_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Task 3: Analyze your model**\n",
    "\n",
    "#### Objective\n",
    "- The goal of this task is to evaluate the quality of the generated text by analyzing how closely it resembles real English. \n",
    "- This is done by comparing the generated text against a predefined list of valid English words.\n",
    "\n",
    "#### Steps\n",
    "**1.** Load a Word List: Use a dictionary of valid English words (words.txt) for reference.\n",
    "\n",
    "**2.** Tokenize the Generated Text: Split the generated text into individual words.\n",
    "\n",
    "**3.** Calculate Valid Word Percentage\n",
    "\n",
    "**4.** Determine how many words in the generated text are valid English words.\n",
    "\n",
    "**5.** Compute the percentage of valid words to assess the accuracy of the trigram model.\n",
    "\n",
    "**6.** Insights: Analyze and interpret the results, highlighting the strengths and weaknesses of the model.\n",
    "\n",
    "#### Purpose\n",
    "This analysis provides a quantitative measure of how well the trigram model captures patterns in the English language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **load_word_list Function**\n",
    "Reads a file of words, converts them to uppercase, and stores them in a set for efficient lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_word_list(filepath):\n",
    "    \n",
    "    with open(filepath, 'r') as file:\n",
    "       \n",
    "        words = {line.strip().upper() for line in file if line.strip()}  \n",
    "\n",
    "    print(f\"Total words loaded: {len(words)}\") \n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Tests for Word List**\n",
    "\n",
    "#### Purpose\n",
    "- This test checks the word list loaded from words.txt for duplicate entries and counts them. this ensures the list is clean and efficient.\n",
    "\n",
    "#### Result\n",
    "- If duplicates exist, their occurrences are displayed; otherwise, a message confirms no duplicates were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words loaded: 45373\n",
      "Found 29 duplicate occurrences in words.txt.\n",
      "Duplicate words with counts: {'ALGOL': 2, 'ARPANET': 2, 'BASIC': 3, 'CALCOMP': 3, 'CENTREX': 2, 'COBOL': 2, 'DUPONT': 2, 'DUPONTS': 2, 'FORTRAN': 2, 'INTERNET': 2, 'MACARTHUR': 2, 'MACDONALD': 2, 'MACDOUGALL': 2, 'MACGREGOR': 2, 'MACINTOSH': 3, 'MACKENZIE': 2, 'MACMILLAN': 2, 'MULTICS': 2, 'PASCAL': 2, 'PEPSICO': 2, 'SIMULA': 2, 'TELNET': 2, 'TENEX': 2, 'TEX': 2, 'ULTRIX': 2, 'UNIX': 2}\n"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "word_list_path = 'reference_data/words.txt'\n",
    "\n",
    "word_list = load_word_list(word_list_path)\n",
    "\n",
    "with open(word_list_path, 'r') as file:\n",
    "    lines = [line.strip().upper() for line in file if line.strip()]\n",
    "    word_counts = Counter(lines) \n",
    "\n",
    "    duplicates = {word: count for word, count in word_counts.items() if count > 1}\n",
    "\n",
    "    duplicate_count = sum(count - 1 for count in duplicates.values()) \n",
    "    if duplicate_count > 0:\n",
    "        print(f\"Found {duplicate_count} duplicate occurrences in words.txt.\")\n",
    "        print(\"Duplicate words with counts:\", duplicates) \n",
    "    else:\n",
    "        print(\"No duplicate words found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Word List Test**\n",
    "\n",
    "#### Purpose\n",
    "- This test verifies that the load_word_list function correctly loads the expected number of words into a set.\n",
    "\n",
    "#### Result\n",
    "- Confirms if the word list contains exactly 45,373 words or highlights a discrepancy in the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1 Passed: Word list loaded successfully with 45373 words.\n"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "\n",
    "# Test 1: Verify that the word list loads correctly\n",
    "expected_word_count = 45373\n",
    "\n",
    "if isinstance(word_list, set) and len(word_list) == expected_word_count:\n",
    "    print(f\"Test 1 Passed: Word list loaded successfully with {expected_word_count} words.\")\n",
    "else:\n",
    "    print(f\"Test 1 Failed: Issue loading word list. Expected {expected_word_count} words, but got {len(word_list)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Splitting Generated Text into Words**\n",
    "\n",
    "- The split_text_into_words function tokenizes the generated text into words by finding sequences of uppercase letters using regular expressions (\\b[A-Z]+\\b). \n",
    "- This function ignores punctuation and spaces, focusing on individual words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_words(text):\n",
    "    \n",
    "    words = re.findall(r'\\b[A-Z]+\\b', text)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Test for split_text_into_words Function**\n",
    "\n",
    "#### Purpose\n",
    "- This test checks if the split_text_into_words function correctly extracts words from the generated text.\n",
    "\n",
    "#### Result\n",
    "- Prints the first 10 words extracted to verify proper tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample words from generated text: ['THIS', 'IS', 'A', 'SAMPLE', 'GENERATED', 'TEXT', 'WITH', 'SOME', 'MADE', 'UP']\n"
     ]
    }
   ],
   "source": [
    "#Tests\n",
    "\n",
    "sample_generated_text = \"THIS IS A SAMPLE GENERATED TEXT WITH SOME MADE-UP WORDS.\"\n",
    "words_in_generated_text = split_text_into_words(sample_generated_text)\n",
    "print(\"Sample words from generated text:\", words_in_generated_text[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating the Percentage of Valid Words\n",
    "\n",
    "The calculate_valid_word_percentage function calculates the percentage of valid English words in the generated text. \n",
    "It uses split_text_into_words to tokenize the generated text and then checks each word against the word_list. \n",
    "The function counts the valid words and calculates the percentage based on the total word count. \n",
    "This percentage provides insight into the quality of the generated text and its resemblance to real English."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_valid_word_percentage(generated_text, word_list):\n",
    "    \n",
    "    words = split_text_into_words(generated_text)\n",
    "    valid_words = [word for word in words if word in word_list]\n",
    "    valid_word_count = len(valid_words)\n",
    "    total_word_count = len(words)\n",
    "    \n",
    "    if total_word_count == 0:\n",
    "        return 0.0, []\n",
    "    \n",
    "    valid_percentage = (valid_word_count / total_word_count) * 100\n",
    "    return valid_percentage, valid_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of valid English words: 38.41%\n",
      "\n",
      "Valid words found in the generated text:\n",
      " ['DIED', 'WHEN', 'SHE', 'HAT', 'THE', 'AS', 'MEN', 'AND', 'THE', 'THEY', 'OF', 'HE', 'WHY', 'OR', 'AD', 'THE', 'LED', 'SAID', 'WE', 'AND', 'THEN', 'OLD', 'OVEN', 'OF', 'IS', 'IN', 'ONE', 'DAY', 'AND', 'WAY', 'MAD', 'TO', 'THE', 'AS', 'IS', 'NAT', 'TO', 'THIS', 'YOUR', 'SING', 'HE', 'OUT', 'COLE', 'OR', 'BED', 'WAS', 'THE', 'THAT', 'IN', 'ON', 'OF', 'IN', 'WAS', 'ONE', 'OF', 'EVE', 'SHE', 'KNOW', 'NED', 'BAD', 'WE', 'LEAD', 'HIP', 'WE', 'THE', 'COME', 'SHE', 'THE', 'HISS', 'HAD', 'WE', 'RE', 'AND', 'LAID', 'HE', 'GO', 'OF', 'THE', 'HAVES', 'BUT', 'YON', 'ORE', 'AN', 'THE', 'OF', 'IN', 'MY', 'OF', 'THE', 'WAS', 'RAND', 'TO', 'GO', 'SLOW', 'BUT', 'WE', 'THE', 'TO', 'TO', 'THE', 'WAS', 'AND', 'OF', 'OLD', 'TO', 'CARD', 'THEY', 'BE', 'ON', 'OFT', 'CRY', 'RE', 'IS', 'ALL', 'HATS', 'FIR', 'AND', 'IS', 'AS', 'IS', 'LOOK', 'HE', 'SHE', 'LONG', 'HAD', 'TO', 'SO', 'THEY', 'FOLD', 'OF', 'THE', 'BE', 'TILL', 'COULD', 'SOME', 'AS', 'HE', 'AND', 'AN', 'HAD', 'UP', 'TO', 'WAY', 'WONG', 'ME', 'AN', 'IF', 'JAW', 'HE', 'BUT', 'HAS', 'HAD', 'PEN', 'AM', 'AN', 'AN', 'SKY', 'FLOG', 'FAN', 'SAY', 'AND', 'IN', 'SO', 'AND', 'THE', 'TO', 'BE', 'TO', 'THE', 'TO', 'RE', 'THE', 'CALL', 'AND', 'AND', 'DOW', 'THE', 'THE', 'TO', 'THIS', 'IS', 'THAT', 'OF', 'KIND', 'BUT', 'ANY', 'TO', 'ALE', 'WIT', 'HE', 'ALL', 'HATE', 'AND', 'KNOW', 'TO', 'RE', 'TO', 'DOW', 'THE', 'SHE', 'PING', 'FOND', 'AT', 'THE', 'OF', 'IN', 'WITS', 'TOLD', 'FLOW', 'HAVE', 'LIKED', 'TO', 'AN', 'HID', 'KING', 'AND', 'AFT', 'TO', 'TO', 'IS', 'IN', 'UP', 'NOT', 'CRY', 'THE', 'AND', 'ME', 'SUCH', 'THE', 'WIT', 'THE', 'EN', 'TO', 'TAX', 'HAT', 'YOU', 'THE', 'PAR', 'DO', 'ASS', 'MET', 'PEA', 'OF', 'SAVE', 'BY', 'FOR', 'HAND', 'DOW', 'RE', 'HE', 'RE', 'OF', 'HALE', 'IN', 'UP', 'ALLY', 'KEY', 'AN', 'RE', 'HEN', 'WAS', 'DING', 'SOME', 'SAY', 'THE', 'THEN', 'OF', 'NOT', 'THE', 'LIED', 'THEY', 'AND', 'SO', 'IN', 'SLY', 'THE', 'TO', 'THE', 'ON', 'THE', 'AND', 'HAT', 'DE', 'THE', 'TO', 'TO', 'OFF', 'OF', 'NO', 'IT', 'THE', 'AL', 'IT', 'SHE', 'WHY', 'FOR', 'HIM', 'UP', 'HOOD', 'WE', 'IN', 'SKY', 'AND', 'DO', 'MAD', 'FAT', 'FOR', 'DAVE', 'GALL', 'OF', 'TO', 'BAD', 'THE', 'HE', 'TIT', 'OF', 'GO', 'BELY', 'HAL', 'THE', 'HE', 'MY', 'IS', 'HE', 'TIME', 'THE', 'WAY', 'BY', 'BEAST', 'WAS', 'TO', 'MY', 'OF', 'AND', 'FORE', 'SAY', 'FOUR', 'THERE', 'IS', 'OF', 'AN', 'OF', 'THE', 'NOW', 'SHE', 'ALL', 'DOOMED', 'FAT', 'LIED', 'LIN', 'HOLD', 'THE', 'GO', 'HIND', 'KNIT', 'GO', 'HE', 'PAY', 'ON', 'AND', 'HISS', 'HAS', 'THIS', 'AND', 'TOM', 'THIS', 'BUT', 'HE', 'BE', 'CALL', 'THE', 'BUT', 'TOM', 'OR', 'BY', 'OF', 'OR', 'HE', 'WILE', 'STALE', 'OF', 'HER', 'ON', 'THE', 'IN', 'AND', 'WORE', 'OF', 'TO', 'OF', 'THE', 'BEEN', 'CAT', 'BONG', 'IT', 'AND', 'SHE', 'FOR', 'IN', 'OF', 'HE', 'OF', 'AH', 'THE', 'ED', 'IN', 'VENT', 'DO', 'FE', 'MEN', 'HE', 'FIST', 'AS', 'THE', 'TO', 'COME', 'AS', 'ONE', 'IN', 'AN', 'SPED', 'DOW', 'TO', 'WERE', 'MORE', 'FIR', 'ALE', 'WHIT', 'BY', 'HIS', 'MAD', 'BUT', 'THERE', 'AND', 'TO', 'MY', 'SAN', 'PAIN', 'THIGH', 'THE', 'OF', 'WAN', 'TO', 'THAT', 'WEDGE', 'HAND', 'THE', 'OF', 'AND', 'THE', 'OF', 'NAP', 'HEY', 'TO', 'NOW', 'ON', 'BURN', 'OF', 'HE', 'ON', 'IS', 'THE', 'OF', 'ROOM', 'ON', 'ALL', 'HE', 'WARDS', 'BED', 'WHAT', 'THE', 'PANS', 'WAS', 'TWAS', 'ALL', 'OF', 'OF', 'TO', 'SUNG', 'HE', 'HE', 'HER', 'HER', 'AND', 'AND', 'IN', 'WE', 'AND', 'BIT', 'THE', 'MAY', 'FIR', 'THE', 'GOT', 'THE', 'ON', 'SAY', 'HAN', 'HER', 'FOR', 'HIM', 'ALL', 'HE', 'THE', 'AND', 'NOR', 'WAS', 'IS', 'WEED', 'BY', 'AS', 'BRAND', 'AND', 'FIR', 'AND', 'ASTERS', 'THE', 'ME', 'THE', 'AND', 'THE', 'AND', 'TOW', 'HE', 'BY', 'ARE', 'THE', 'HER', 'HALE', 'HANDS', 'IS', 'TOO', 'TO', 'TO', 'BY', 'AT', 'THE', 'THE', 'AFT', 'PER', 'ON', 'TO', 'MUCH', 'THEY', 'OF', 'BEEP', 'TO', 'SING', 'SHE', 'THE', 'BE', 'HAT', 'IS', 'CAME', 'HOW', 'HE', 'IN', 'THE', 'HIS', 'THE', 'CARE', 'WING', 'LAND', 'AND', 'THEM', 'TO', 'KNOT', 'THEY', 'AS', 'SEAR', 'IT', 'THE', 'OF', 'NOW', 'SAN', 'ONLY', 'THE', 'FEW', 'SO', 'GOD', 'TO', 'THE', 'PER', 'THE', 'THE', 'NEW', 'MOCK', 'AN', 'THE', 'EM', 'THEN', 'SO', 'HIP', 'BIT', 'TO', 'AND', 'WE', 'RE', 'HE', 'ME', 'ALL', 'LOW', 'MEND', 'HE', 'AS', 'BUT', 'HAND', 'NOT', 'ME', 'NAT', 'AS', 'FIT', 'BY', 'EVER', 'HAT', 'ON', 'NOW', 'THE', 'ME', 'DO', 'THE', 'SON', 'OF', 'WITS', 'WAVE', 'SORES', 'RE', 'BE', 'THE', 'SAY', 'OF', 'HIS', 'HEAT', 'THE', 'DIN', 'THEY', 'SO', 'GLAND', 'THE', 'THE', 'BUT', 'TO', 'THE', 'ANT', 'ARK', 'THAT', 'OF', 'TIME', 'HAND', 'UP', 'ME', 'CON', 'BY', 'OR', 'THIS', 'BLUE', 'THIS', 'FORT', 'THE', 'THE', 'HAVEN', 'RIGHT', 'SHE', 'ALL', 'AND', 'IN', 'BY', 'BIT', 'TORE', 'HAD', 'LOWS', 'HAT', 'WE', 'WE', 'FOR', 'THE', 'RAN', 'ELF', 'SAKE', 'WHAT', 'TO', 'BUT', 'THE', 'HER', 'YOU', 'AD', 'NOT', 'GO', 'SAY', 'AS', 'ANT', 'ON', 'HAT', 'OF', 'FOR', 'LIKED', 'HAT', 'OF', 'SHEARED', 'HIS', 'WAS', 'HIS', 'ME', 'RE', 'RE', 'LIPS', 'OF', 'SEER', 'TO', 'WAS', 'THEY', 'AN', 'TO', 'BUT', 'HERE', 'ALBEIT', 'AND', 'HE', 'FEEL', 'SAME', 'UP']\n"
     ]
    }
   ],
   "source": [
    "valid_percentage, valid_words = calculate_valid_word_percentage(generated_text_output, word_list)\n",
    "print(f\"Percentage of valid English words: {valid_percentage:.2f}%\")\n",
    "print(\"\\nValid words found in the generated text:\\n\", valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "- The trigram model effectively generates text based on the input data patterns.\n",
    "- The generated text demonstrates a good resemblance to English based on the valid word percentage that is produced wach time.\n",
    "- The results validate the effectiveness of trigram-based language models for text generation, particularly in capturing common sequences and grammatical patterns in English.\n",
    "- While some limitations are observed, such as occasional nonsensical outputs, the model performs well overall given its reliance on simple statistical patterns.- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trigram_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
